\relax 
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\abx@aux@refcontext{apa/global//global/global/global}
\HyPL@Entry{0<</S/D>>}
\babel@aux{french}{}
\babel@aux{english}{}
\HyPL@Entry{1<</S/D>>}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{wang2003_nn}
\abx@aux@segm{0}{0}{wang2003_nn}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{bishop2006_pattern}
\abx@aux@segm{0}{0}{bishop2006_pattern}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{goodfellow_2016}
\abx@aux@segm{0}{0}{goodfellow_2016}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{rosenblatt1958_perceptron}
\abx@aux@segm{0}{0}{rosenblatt1958_perceptron}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{haykin1994_ml}
\abx@aux@segm{0}{0}{haykin1994_ml}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{goodfellow_2016}
\abx@aux@segm{0}{0}{goodfellow_2016}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{cybenko1989_approx}
\abx@aux@segm{0}{0}{cybenko1989_approx}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\abx@aux@page{1}{2}
\abx@aux@page{2}{2}
\abx@aux@page{3}{2}
\abx@aux@page{4}{2}
\abx@aux@page{5}{2}
\abx@aux@page{6}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Neural Network} | A typical structure.}}{2}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:nn}{{1}{2}{\textbf {Neural Network} | A typical structure}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory and methods}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The universal approximation theorem}{2}{subsection.2.1}\protected@file@percent }
\abx@aux@page{7}{2}
\newlabel{th:theoexample}{{2.1}{2}{Universal approximation}{tcb@cnt@mytheo.2.1}{}}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{hornik1991_approximation}
\abx@aux@segm{0}{0}{hornik1991_approximation}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{goodfellow_2016}
\abx@aux@segm{0}{0}{goodfellow_2016}
\abx@aux@page{8}{3}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Structure of a Neural Network}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}The Feed-forward algorithm}{3}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Simple perceptron model with 1-D input}{3}{subsubsection.2.2.1}\protected@file@percent }
\abx@aux@page{9}{3}
\@writefile{toc}{\contentsline {paragraph}{Generalization to a multi-layer network with multiple inputs}{3}{equation.5}\protected@file@percent }
\newlabel{eq:ff}{{6}{3}{Generalization to a multi-layer network with multiple inputs}{equation.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Implementation}{3}{equation.7}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Feedforward}}{3}{algorithm.1}\protected@file@percent }
\newlabel{alg:ff}{{1}{3}{Feedforward}{algorithm.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Simple perceptron model} | In blue the different layers, in orange the functions.}}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:simpleperc}{{2}{4}{\textbf {Simple perceptron model} | In blue the different layers, in orange the functions}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}The Backpropagation algorithm}{4}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Formalism of backpropagation}{4}{equation.8}\protected@file@percent }
\newlabel{eq:deltaL}{{14}{4}{Formalism of backpropagation}{equation.14}{}}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{hastie_stat2009}
\abx@aux@segm{0}{0}{hastie_stat2009}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{goodfellow_2016}
\abx@aux@segm{0}{0}{goodfellow_2016}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{tieleman2012rmsprop}
\abx@aux@segm{0}{0}{tieleman2012rmsprop}
\abx@aux@refcontext{apa/apasortcite//global/global/global}
\abx@aux@cite{0}{kingma:adam}
\abx@aux@segm{0}{0}{kingma:adam}
\@writefile{toc}{\contentsline {paragraph}{Implementation}{5}{equation.18}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Backpropagation}}{5}{algorithm.2}\protected@file@percent }
\newlabel{alg:bp}{{2}{5}{Backpropagation}{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Training the Neural Network}{5}{subsubsection.2.2.3}\protected@file@percent }
\abx@aux@page{10}{5}
\abx@aux@page{11}{5}
\abx@aux@page{12}{5}
\abx@aux@page{13}{5}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Activation functions}{5}{subsubsection.2.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Cost functions}{5}{subsection.2.3}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{30CF001EA9FABCD30EC5752BC48B40BB}
\gdef \@abspage@last{6}
